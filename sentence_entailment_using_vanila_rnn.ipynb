{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentance entailment with Pytorch using vanila RNN/LSTM/GRU\n",
    "## This notebook has the follwing topics \n",
    "    1. Dataset Preprocessing using torchtext\n",
    "    2. Training details \n",
    "    3. Inference\n",
    "## Observations\n",
    "    1. Since the architecture is very simple the accuracy is very bad\n",
    "    2. The model tends to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:17.562957Z",
     "start_time": "2021-01-31T15:04:17.024966Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:17.936909Z",
     "start_time": "2021-01-31T15:04:17.934861Z"
    }
   },
   "outputs": [],
   "source": [
    "## GLOBAL SETTINGS\n",
    "SEED = 2021\n",
    "BATCH_SIZE = 32\n",
    "visualize_index = 10 # Index to be used to test/visualize items\n",
    "label_dict = {0 : 'contradiction', 1 : 'entailment', 2 : 'neutral'} # output label and there index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Preprocessing using torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:18.821544Z",
     "start_time": "2021-01-31T15:04:18.771265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentence pairs : 9349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A white dog with long hair jumps to catch a re...</td>\n",
       "      <td>A white chihuahua mix with long curly hair is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A young girl wearing a pink coat plays with a ...</td>\n",
       "      <td>A girl is wearing a blue jacket.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>two wrestlers wrestling, the one on the bottom...</td>\n",
       "      <td>The good friends eat ice cream together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>entailment</td>\n",
       "      <td>A man in a black shirt is playing golf outside.</td>\n",
       "      <td>The man wearing the black shirt plays a game o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A woman with dark hair wearing a dark shirt, j...</td>\n",
       "      <td>A reporter is doing a live news report.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>entailment</td>\n",
       "      <td>A young child is looking at a commuter train s...</td>\n",
       "      <td>The child is on a train seat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A football team getting ready for the coin tos...</td>\n",
       "      <td>The stadium was packed with people.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Two dogs playing in the snow.</td>\n",
       "      <td>The two dogs are inside sleeping by the firepl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>The streets are busy and people contemplate th...</td>\n",
       "      <td>People are screaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>entailment</td>\n",
       "      <td>The dog is walking in the snow.</td>\n",
       "      <td>The snow is outside</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gold_label                                          sentence1  \\\n",
       "8491        neutral  A white dog with long hair jumps to catch a re...   \n",
       "234   contradiction  A young girl wearing a pink coat plays with a ...   \n",
       "3104  contradiction  two wrestlers wrestling, the one on the bottom...   \n",
       "1806     entailment    A man in a black shirt is playing golf outside.   \n",
       "4096        neutral  A woman with dark hair wearing a dark shirt, j...   \n",
       "8132     entailment  A young child is looking at a commuter train s...   \n",
       "7152  contradiction  A football team getting ready for the coin tos...   \n",
       "5114  contradiction                      Two dogs playing in the snow.   \n",
       "9174  contradiction  The streets are busy and people contemplate th...   \n",
       "8295     entailment                    The dog is walking in the snow.   \n",
       "\n",
       "                                              sentence2  \n",
       "8491  A white chihuahua mix with long curly hair is ...  \n",
       "234                    A girl is wearing a blue jacket.  \n",
       "3104            The good friends eat ice cream together  \n",
       "1806  The man wearing the black shirt plays a game o...  \n",
       "4096            A reporter is doing a live news report.  \n",
       "8132                      The child is on a train seat.  \n",
       "7152                The stadium was packed with people.  \n",
       "5114  The two dogs are inside sleeping by the firepl...  \n",
       "9174                               People are screaming  \n",
       "8295                                The snow is outside  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv(\"../dataset/assignment_data_set/train.csv\")\n",
    "print(f\"Number of training sentence pairs : {train_df.shape[0]}\")\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "train_df.sample(visualize_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:19.500047Z",
     "start_time": "2021-01-31T15:04:19.482177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "entailment       3166\n",
       "contradiction    3114\n",
       "neutral          3069\n",
       "Name: gold_label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training labels')\n",
    "train_df.gold_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:20.675594Z",
     "start_time": "2021-01-31T15:04:20.225184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to create sentence pairs\n",
    "def create_sen_pair(dataframe):\n",
    "    final_df = []\n",
    "    for idx in tqdm(dataframe.index):\n",
    "        each_sen_pair = [\n",
    "            dataframe.iloc[idx][\"sentence1\"], dataframe.iloc[idx][\"sentence2\"]\n",
    "        ]\n",
    "        label = dataframe.iloc[idx][\"gold_label\"]\n",
    "        final_df.append([each_sen_pair, label])\n",
    "    return final_df\n",
    "\n",
    "# Tokinization\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:21.985372Z",
     "start_time": "2021-01-31T15:04:20.676661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9349/9349 [00:01<00:00, 7162.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df_processed = create_sen_pair(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:23.114169Z",
     "start_time": "2021-01-31T15:04:22.422331Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9349/9349 [00:00<00:00, 13758.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------check out one example---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sen_1': ['three',\n",
       "  'women',\n",
       "  ',',\n",
       "  'two',\n",
       "  'wearing',\n",
       "  'red',\n",
       "  'shirts',\n",
       "  'and',\n",
       "  'one',\n",
       "  'wearing',\n",
       "  'a',\n",
       "  'purple',\n",
       "  'shirt',\n",
       "  ',',\n",
       "  'and',\n",
       "  'a',\n",
       "  'man',\n",
       "  ',',\n",
       "  'wearing',\n",
       "  'a',\n",
       "  'light',\n",
       "  'blue',\n",
       "  'shirt',\n",
       "  ',',\n",
       "  'jump',\n",
       "  'on',\n",
       "  'a',\n",
       "  'basketball',\n",
       "  'court',\n",
       "  'with',\n",
       "  'balls',\n",
       "  'in',\n",
       "  'their',\n",
       "  'hands',\n",
       "  '.'],\n",
       " 'sen_2': ['three', 'people', \"'s\", 'are', 'eating', 'in', 'hotel', '.'],\n",
       " 'label': 'contradiction'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process data using torchtext FIELD\n",
    "\n",
    "SEN_1 = Field(sequential=True,\n",
    "              tokenize=tokenize_en,\n",
    "              use_vocab=True,\n",
    "              lower=True,\n",
    "              batch_first=True)\n",
    "SEN_2 = Field(sequential=True,\n",
    "              tokenize=tokenize_en,\n",
    "              use_vocab=True,\n",
    "              lower=True,\n",
    "              batch_first=True)\n",
    "LABEL =  data.LabelField()\n",
    "\n",
    "fields = [('sen_1', SEN_1), ('sen_2', SEN_2),('label', LABEL)]\n",
    "example = [\n",
    "    data.Example.fromlist([train_df_processed[i][0][0],train_df_processed[i][0][1],train_df_processed[i][1]],\n",
    "                          fields) for i in tqdm(range(len(train_df_processed)))\n",
    "]\n",
    "\n",
    "print('---------------check out one example---------------')\n",
    "vars(example[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:23.499886Z",
     "start_time": "2021-01-31T15:04:23.487372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------check out train and validation dataset---------------\n",
      "{'sen_1': ['a', 'young', 'child', ',', 'wearing', 'a', 'pink', '-', 'polkadotted', 'outfit', ',', 'smiles', 'at', 'the', 'camera', 'as', 'she', 'lays', 'on', 'a', 'white', ',', 'shaggy', 'rug', '.'], 'sen_2': ['the', 'child', 'is', 'in', 'stripe', ','], 'label': 'contradiction'}\n"
     ]
    }
   ],
   "source": [
    "# creating dataset\n",
    "train_Dataset = data.Dataset(example, fields)\n",
    "(train_data, valid_data) = train_Dataset.split(split_ratio=[0.90, 0.10],\n",
    "                                               random_state=random.seed(SEED))\n",
    "\n",
    "print('---------------check out train and validation dataset---------------')\n",
    "print(vars(train_data.examples[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:23.932458Z",
     "start_time": "2021-01-31T15:04:23.925997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 8414\n",
      "Number of validation examples: 935\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:24.912807Z",
     "start_time": "2021-01-31T15:04:24.298911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input vocab :  4066 4621\n",
      "Size of label vocab :  3\n",
      "Top 10 words appreared repeatedly : [('a', 15756), ('.', 8030), ('in', 5118), ('the', 3803), ('and', 3013), ('on', 2690), ('of', 2499), ('man', 2469), ('is', 2294), ('with', 2261)]\n",
      "Labels :  defaultdict(None, {'entailment': 0, 'contradiction': 1, 'neutral': 2})\n"
     ]
    }
   ],
   "source": [
    "# use pretrained glove embedding for words\n",
    "SEN_1.build_vocab(train_data,vectors=\"glove.6B.100d\")\n",
    "SEN_2.build_vocab(train_data,vectors=\"glove.6B.100d\")\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print('Size of input vocab : ', len(SEN_1.vocab),len(SEN_2.vocab))\n",
    "print('Size of label vocab : ', len(LABEL.vocab))\n",
    "print('Top 10 words appreared repeatedly :',\n",
    "      list(SEN_1.vocab.freqs.most_common(10)))\n",
    "print('Labels : ', LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:24.948972Z",
     "start_time": "2021-01-31T15:04:24.914087Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train_data, valid_data),\n",
    "                                                            batch_size = BATCH_SIZE, \n",
    "                                                            sort=False,\n",
    "                                                            device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:26.591671Z",
     "start_time": "2021-01-31T15:04:25.329525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking out one batch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 36]), torch.Size([32, 28]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('checking out one batch')\n",
    "x = next(iter(train_iterator))\n",
    "x.sen_1.shape,x.sen_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Training details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:26.765956Z",
     "start_time": "2021-01-31T15:04:26.757243Z"
    }
   },
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,\n",
    "                 n_layers,dropout):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers=n_layers,\n",
    "                          batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, sen_1, sen_2):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "\n",
    "        embedded_sen1 = self.dropout(self.embedding(sen_1))\n",
    "        embedded_sen2 = self.dropout(self.embedding(sen_2))\n",
    "        x = torch.cat([embedded_sen1, embedded_sen2], 1)\n",
    "        _, hidden_t = self.rnn(x)\n",
    "        output = self.fc(hidden_t.squeeze(0))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:27.483913Z",
     "start_time": "2021-01-31T15:04:27.447915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (embedding): Embedding(8687, 100)\n",
      "  (rnn): GRU(100, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SEN_1.vocab)+len(SEN_2.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_LAYERS = 1\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.3\n",
    "\n",
    "model = classifier(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:28.220032Z",
     "start_time": "2021-01-31T15:04:28.211227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,144,415 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:28.787888Z",
     "start_time": "2021-01-31T15:04:28.769381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2709,  0.0440, -0.0203,  ..., -0.4923,  0.6369,  0.2364],\n",
       "        ...,\n",
       "        [-0.3389,  0.2919,  0.2993,  ...,  0.2409,  0.2894, -0.6609],\n",
       "        [-0.0205, -0.4512,  0.6993,  ...,  0.0381,  0.2786,  0.2889],\n",
       "        [-0.0473,  0.4594,  1.0032,  ..., -0.2536,  0.3862,  0.1045]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained embeddings \n",
    "pretrained_embeddings = torch.cat((SEN_1.vocab.vectors,SEN_2.vocab.vectors),dim=0)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:30.793637Z",
     "start_time": "2021-01-31T15:04:30.777003Z"
    }
   },
   "outputs": [],
   "source": [
    "# training configs\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:31.411122Z",
     "start_time": "2021-01-31T15:04:31.400981Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy metric\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:32.153765Z",
     "start_time": "2021-01-31T15:04:32.146292Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.sen_1,batch.sen_2)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:32.569836Z",
     "start_time": "2021-01-31T15:04:32.562636Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.sen_1,batch.sen_2)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:33.028225Z",
     "start_time": "2021-01-31T15:04:33.024424Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:55.001411Z",
     "start_time": "2021-01-31T15:04:33.636303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.094 | Train Acc: 36.06%\n",
      "\t Val. Loss: 1.089 |  Val. Acc: 39.14%\n",
      "Epoch: 02 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.052 | Train Acc: 43.36%\n",
      "\t Val. Loss: 1.028 |  Val. Acc: 46.28%\n",
      "Epoch: 03 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 1.002 | Train Acc: 49.31%\n",
      "\t Val. Loss: 1.006 |  Val. Acc: 47.47%\n",
      "Epoch: 04 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.947 | Train Acc: 54.38%\n",
      "\t Val. Loss: 1.000 |  Val. Acc: 49.29%\n",
      "Epoch: 05 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.884 | Train Acc: 59.88%\n",
      "\t Val. Loss: 0.966 |  Val. Acc: 53.72%\n",
      "Epoch: 06 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.817 | Train Acc: 64.12%\n",
      "\t Val. Loss: 0.965 |  Val. Acc: 54.55%\n",
      "Epoch: 07 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.748 | Train Acc: 67.86%\n",
      "\t Val. Loss: 0.990 |  Val. Acc: 55.34%\n",
      "Epoch: 08 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.695 | Train Acc: 70.87%\n",
      "\t Val. Loss: 1.004 |  Val. Acc: 54.66%\n",
      "Epoch: 09 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.640 | Train Acc: 73.84%\n",
      "\t Val. Loss: 1.023 |  Val. Acc: 54.51%\n",
      "Epoch: 10 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.587 | Train Acc: 76.27%\n",
      "\t Val. Loss: 1.054 |  Val. Acc: 54.03%\n",
      "Epoch: 11 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.544 | Train Acc: 78.68%\n",
      "\t Val. Loss: 1.097 |  Val. Acc: 54.35%\n",
      "Epoch: 12 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.498 | Train Acc: 80.10%\n",
      "\t Val. Loss: 1.172 |  Val. Acc: 54.82%\n",
      "Epoch: 13 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.463 | Train Acc: 81.26%\n",
      "\t Val. Loss: 1.208 |  Val. Acc: 53.62%\n",
      "Epoch: 14 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.417 | Train Acc: 83.69%\n",
      "\t Val. Loss: 1.318 |  Val. Acc: 53.76%\n",
      "Epoch: 15 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.386 | Train Acc: 84.82%\n",
      "\t Val. Loss: 1.385 |  Val. Acc: 54.82%\n",
      "Epoch: 16 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.348 | Train Acc: 86.56%\n",
      "\t Val. Loss: 1.417 |  Val. Acc: 55.82%\n",
      "Epoch: 17 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.310 | Train Acc: 87.75%\n",
      "\t Val. Loss: 1.566 |  Val. Acc: 53.30%\n",
      "Epoch: 18 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.279 | Train Acc: 89.06%\n",
      "\t Val. Loss: 1.658 |  Val. Acc: 51.06%\n",
      "Epoch: 19 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.261 | Train Acc: 89.74%\n",
      "\t Val. Loss: 1.574 |  Val. Acc: 52.41%\n",
      "Epoch: 20 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: 0.231 | Train Acc: 91.28%\n",
      "\t Val. Loss: 1.691 |  Val. Acc: 52.93%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'final_model_rnn.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:04:59.624825Z",
     "start_time": "2021-01-31T15:04:59.619805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functiont for testing\n",
    "def check_similarity(s1, s2):\n",
    "    indexed_1 = [SEN_1.vocab.stoi[t] for t in s1]\n",
    "    indexed_2 = [SEN_2.vocab.stoi[t] for t in s2]\n",
    "    tensor_1, tensor_2 = torch.LongTensor(indexed_1).to(\n",
    "        device), torch.LongTensor(indexed_2).to(device)\n",
    "    tensor_1 = tensor_1.unsqueeze(0)\n",
    "    tensor_2 = tensor_2.unsqueeze(0)\n",
    "    preds = model(tensor_1, tensor_2)\n",
    "    max_preds = preds.argmax(dim=1).to('cpu').numpy()[0]\n",
    "    return act_label, label_dict[max_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T15:05:00.380849Z",
     "start_time": "2021-01-31T15:05:00.361275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing the model with the following sentence pair \n",
      "\n",
      "sentence 1 -->  an overweight man in a blue and black hooded sweatshirt works on a laptop computer outdoors .\n",
      "sentence 2 -->  a heavyset man in a hoodie works in a laptop while outside .\n",
      "actual label -->  entailment\n",
      "predicted label -->  contradiction\n"
     ]
    }
   ],
   "source": [
    "# Testing from validation data as we are not training on validation data\n",
    "\n",
    "index = random.randint(0,len(valid_data.examples))\n",
    "s1,s2 = valid_data[index].sen_1,valid_data[index].sen_2\n",
    "act_label = valid_data[index].label\n",
    "pred_label = check_similarity(s1,s2)\n",
    "\n",
    "print('testing the model with the following sentence pair \\n')\n",
    "print('sentence 1 --> ', \" \".join(s1))\n",
    "print('sentence 2 --> ', \" \".join(s2))\n",
    "print('actual label --> ',act_label)\n",
    "print('predicted label --> ',pred_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
